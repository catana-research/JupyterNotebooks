{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Keras\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update, dubbed Keras 2, has been changed to adapt to TensorFlow API better, allowing developers to mix and match TensorFlow and Keras components together. Since the software runs on TensorFlow and Theano, there is no performance cost to using Keras compared to the other more complex frameworks.\n",
    "Keras is more specialized for deep learning than TensorFlow or Theano. It’s “higher-level” and “abstracts away a lot of details that most users don’t need to know about,”\n",
    "Instead of dealing with several lines of messy code, developers can directly input deep learning models and customize their own neural nets by clipping together different components or “layers.”\n",
    "It provides a way for researchers to quickly try out different configurations of their models, reducing the time it takes to set up new experiments.\n",
    "\n",
    "https://medium.com/implodinggradients/tensorflow-or-keras-which-one-should-i-learn-5dd7fa3f9ca0 \n",
    "https://www.datacamp.com/community/tutorials/deep-learning-python \n",
    "https://www.kdnuggets.com/2017/10/seven-steps-deep-learning-keras.html \n",
    "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/ \n",
    "https://machinelearningmastery.com/introduction-python-deep-learning-library-keras/ \n",
    "http://adventuresinmachinelearning.com/keras-lstm-tutorial/ \n",
    "https://tensorflow.rstudio.com/blog/keras-customer-churn.html \n",
    "https://www.kaggle.com/johanvandenheuvel/lstm-model-of-stockdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General definitions\n",
    "\n",
    "**Epoch** - One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.\n",
    "\n",
    "As the number of epochs increases, more number of times the weight are changed in the neural network and the curve goes from underfitting to optimal to overfitting curve.\n",
    "\n",
    "**Batch Size** - Total number of training examples present in a single batch.\n",
    "\n",
    "In gradient descent algorithms, you can calculate the sum of gradients with respect to several examples and then update the parameters using this cumulative gradient. If you ‘see’ all training examples before one ‘update’, then it’s called full batch learning. If you use only one example, it’s called stochastic gradient descent (online learning). If you use a small batch of examples, it’s often called mini-batch learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras definitions\n",
    "\n",
    "The _Sequential_ model is a linear stack of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisers\n",
    "\n",
    "https://keras.io/optimizers/\n",
    "\n",
    "```SGD``` - Stochastic gradient descent optimizer.\n",
    "\n",
    "```RMSprop``` - RMSprop, this optimizer is usually a good choice for recurrent neural networks.\n",
    "\n",
    "### Loss functions\n",
    "\n",
    "https://keras.io/losses/\n",
    "\n",
    "```binary_crossentropy``` - For labels with two options\n",
    "\n",
    "### Models\n",
    "\n",
    "https://keras.io/models/about-keras-models/\n",
    "\n",
    "### Layers\n",
    "\n",
    "https://keras.io/layers/about-keras-layers/\n",
    "\n",
    "#### Core layers\n",
    "\n",
    "```Dense``` - Regular densely-connected NN layer, which implements the operation: ```output = activation(dot(input, kernel) + bias)```, where ```kernel``` is a weights matrix created by the layer, and ```bias``` is a bias vector created by the layer\n",
    "\n",
    "```Activation``` - Applies an activation function to an output.\n",
    "\n",
    "```Dropout``` - Dropout consists in randomly setting a fraction ```rate``` of input units to 0 at each update during training time, which helps prevent overfitting.\n",
    "\n",
    "##### Convolutional layers\n",
    "\n",
    "```Conv1D``` - This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "https://github.com/keras-team/keras/tree/master/examples \n",
    "\n",
    "\n",
    "### Prediction\n",
    "\n",
    "```python\n",
    "model.predict_classes(rowx, verbose=0)\n",
    "```\n",
    "\n",
    "### Padding\n",
    "\n",
    "```python\n",
    "# Sequences that are shorter than `num_timesteps` are padded with `value` at the end.\n",
    "# Sequences longer than `num_timesteps` are truncated so that they fit the desired length.\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "```\n",
    "\n",
    "### Dropout\n",
    "\n",
    "```python\n",
    "#     Dropout consists in randomly setting\n",
    "#    a fraction `rate` of input units to 0 at each update during training time,\n",
    "#    which helps prevent overfitting.\n",
    "model.add(Dropout(0.2))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Datasets\n",
    "\n",
    "```python\n",
    "from keras.datasets import imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=100)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
