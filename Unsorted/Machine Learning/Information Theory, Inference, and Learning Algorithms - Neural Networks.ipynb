{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 38 - Introduction to Neural Networks (pg 480)\n",
    "\n",
    "<b>Supervised neural networks</b> are given data in the form of inputs and tar-\n",
    "gets, the targets being a teacher's specification of what the neural network's\n",
    "response to the input should be.\n",
    "\n",
    "<b>Unsupervised neural networks</b> are given data in an undivided form { simply\n",
    "a set of examples {x}.\n",
    "\n",
    "![Image](Images/Ch38_1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 39 - The Single Neuron as a Classifier (pg 483)\n",
    "\n",
    "![Image](Images/Ch39_1.PNG)\n",
    "![Image](Images/Ch39_2.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central idea of supervised neural networks given an input vector $x$, and a target $t$, is to learn a model of the relationship between $x$ and $t$. A\n",
    "successfully trained network will, for any given $x$, give an output $y$ that is\n",
    "close (in some sense) to the target value $t$. Training the network involves\n",
    "searching in the weight space of the network for a value of $w$ that produces a\n",
    "function that fits the provided training data well.\n",
    "\n",
    "Typically an <b>objective function</b> or <b>error function</b> is defined, as a function of $w$, to measure how well the network with weights set to $w$ solves the task. The objective function is a sum of terms, one for each input/target pair {x, t}, measuring how close the output y(x; w) is to the target $t$. \n",
    "\n",
    "The training process is an exercise in function minimization i.e., adjusting $w$ in such a way as to find a $w$ that minimizes the objective function. For general feedforward neural networks the backpropagation algorithm efficiently evaluates the gradient of the output $y$ with respect to the parameters $w$, and thence the gradient of the objective function with respect to $w$.\n",
    "\n",
    "We can then write down the following error function:\n",
    "$$G(w) = - \\sum_{n} \\left[t^{(n)} \\ln y\\left(x^{(n)};w\\right) + (1 - t^{(n)}) \\ln\\left(1 - y\\left(x^{(n)};w\\right)\\right) \\right]$$\n",
    "The objective function is bounded below by zero and only attains this value if $y(x^{(n)};w) = t^{(n)}$ for all $n$.\n",
    "\n",
    "\n",
    "The <b>backpropagation</b> algorithm:\n",
    "$$g_{j} = \\frac{\\delta G}{\\delta w_{j}} = \\sum_{n=1}^{N} -(t^{(n)} - y^{(n)})x^{(n)}_{j}$$\n",
    "\n",
    "The simplest thing to do with a gradient of an error function is to descend it.\n",
    "\n",
    "<b>On-line learning algorithm</b>\n",
    "\n",
    "The teacher supplies a target value $t \\in {0, 1}$ which says what the correct answer is for the given input. We compute the error signal:\n",
    "$$e = t - y$$\n",
    "then adjust the weights $w$ in a direction that would reduce the magnitude\n",
    "of this error:\n",
    "$$\\Delta w_{i} = \\eta ex_{i}$$\n",
    "where $\\eta$ is the learning rate. Commonly $\\eta$ is set by trial and error to a constant value or to a decreasing function of simulation time $\\tau$ such as\n",
    "$\\eta_{0}/\\tau$.\n",
    "\n",
    "An alternative paradigm is to go through a batch of examples, computing the outputs and errors and accumulating the changes at the end of the batch (<b>Batch learning</b>).\n",
    "\n",
    "This batch learning algorithm is a gradient descent algorithm, whereas the\n",
    "on-line algorithm is a stochastic gradient descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Overfitting</b>\n",
    "\n",
    "An ad hoc solution to overfitting is to use early stopping, that is, use\n",
    "an algorithm originally intended to minimize the error function G(w), then\n",
    "prevent it from doing so by halting the algorithm at some point.\n",
    "\n",
    "A more principled solution to overfitting makes use of regularization. Regularization\n",
    "involves modifying the objective function in such a way as to incorporate\n",
    "a bias against the sorts of solution $w$ which we dislike.\n",
    "\n",
    "We modify the objective function to:\n",
    "$$M(w) = G(w) + \\alpha E_{W}(w)$$\n",
    "where the simplest choice of regularizer is the weight decay regularizer\n",
    "$$E_{W}(w) =\\frac{1}{2}\\sum_{i}w^{2}_{i}$$\n",
    "The regularization constant $\\alpha$ is called the weight decay rate. This additional\n",
    "term favours small values of $w$ and decreases the tendency of a model to overfit\n",
    "fine details of the training data. The quantity $\\alpha$ is known as a hyperparameter.\n",
    "\n",
    "Gradient descent with a step size $\\eta$ is in general not the most efficient way to\n",
    "minimize a function. Most neural network experts use more advanced optimizers such as conjugate gradient algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 40 - Capacity of a Single Neuron (pg 495)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Chapter 41 - Learning as Inference (pg 504)\n",
    "# Chapter 42 - Hopfield Networks (pg 517)\n",
    "# Chapter 43 - Boltzmann Machines (pg 534)\n",
    "# Chapter 44 - Supervised Learning in Multilayer Networks (pg 539)\n",
    "# Chapter 45 - Gaussian Processes (pg 547)\n",
    "# Chapter 46 - Deconvolution (pg 561)\n",
    "\n",
    "# Appendix - (pg 610)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
